{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356a6482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:00:13.250358Z",
     "iopub.status.busy": "2025-08-22T20:00:13.249936Z",
     "iopub.status.idle": "2025-08-22T20:00:13.259528Z",
     "shell.execute_reply": "2025-08-22T20:00:13.258733Z",
     "shell.execute_reply.started": "2025-08-22T20:00:13.250329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print(load_dotenv('../.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71795ff1-d6a7-448d-8b55-88bbd1ed3dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:00:13.261125Z",
     "iopub.status.busy": "2025-08-22T20:00:13.260845Z",
     "iopub.status.idle": "2025-08-22T20:00:15.269769Z",
     "shell.execute_reply": "2025-08-22T20:00:15.268779Z",
     "shell.execute_reply.started": "2025-08-22T20:00:13.261096Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Annotated, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90594692-6784-4966-bb89-50aec2202fa3",
   "metadata": {},
   "source": [
    "# Ingest Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2057fe-7392-4892-abb1-85a32c14e35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:00:15.274699Z",
     "iopub.status.busy": "2025-08-22T20:00:15.274383Z",
     "iopub.status.idle": "2025-08-22T20:00:15.278469Z",
     "shell.execute_reply": "2025-08-22T20:00:15.277793Z",
     "shell.execute_reply.started": "2025-08-22T20:00:15.274668Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(docs_list):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=50,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    return doc_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d061813f-ebc0-432c-91ec-3b42b15c30b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:00:16.000617Z",
     "iopub.status.busy": "2025-08-22T20:00:16.000165Z",
     "iopub.status.idle": "2025-08-22T20:00:28.082058Z",
     "shell.execute_reply": "2025-08-22T20:00:28.081171Z",
     "shell.execute_reply.started": "2025-08-22T20:00:16.000586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411196bbd4414610a8e35e8bdb68b745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db237c72120844b8a32263a6fba55812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4511b363b63c4e01831dc835a87ec208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'filename': 'perf_train_cpu_many.md'}, page_content='\"\\\\n\\\\n# Efficient Training on Multiple CPUs\\\\n\\\\nWhen training on a single CPU is too slow, we can use multiple CPUs. This guide focuses on PyTorch-based DDP enabling distributed CPU training efficiently.\\\\n\\\\n## Intel\\\\u00ae oneCCL Bindings for PyTorch\\\\n\\\\n[Intel\\\\u00ae oneCCL](https://github.com/oneapi-src/oneCCL) (collective communications library) is a library for efficient distributed deep learning training implementing such collectives like allreduce, allgather, alltoall. For more information on oneCCL, please refer to the [oneCCL documentation](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html) and [oneCCL specification](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html).\\\\n\\\\nModule `oneccl_bindings_for_pytorch` (`torch_ccl` before version 1.12)  implements PyTorch C10D ProcessGroup API and can be dynamically loaded as external ProcessGroup and only works on Linux platform now\\\\n\\\\nCheck more detailed information for [oneccl_bind_pt](https://github.com/intel/torch-ccl).\\\\n\\\\n### Intel\\\\u00ae oneCCL Bindings for PyTorch installation:\\\\n\\\\nWheel files are available for the following Python versions:\\\\n\\\\n| Extension Version | Python 3.6 | Python 3.7 | Python 3.8 | Python 3.9 | Python 3.10 |\\\\n\\\\n| :---------------: | :--------: | :--------: | :--------: | :--------: | :---------: |\\\\n\\\\n| 1.13.0            |            | \\\\u221a          | \\\\u221a          | \\\\u221a          | \\\\u221a           |\\\\n\\\\n| 1.12.100          |            | \\\\u221a          | \\\\u221a          | \\\\u221a          | \\\\u221a           |\\\\n\\\\n| 1.12.0            |            | \\\\u221a          | \\\\u221a          | \\\\u221a          | \\\\u221a           |\\\\n\\\\n| 1.11.0            |            |')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/m-ric/transformers_documentation_en\n",
    "transformers_doc = HuggingFaceDatasetLoader(\"m-ric/transformers_documentation_en\", \"text\")\n",
    "docs = preprocess_dataset(transformers_doc.load()[:50])\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10741d4b-020d-436a-bdfb-ad0ba4424ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:06:10.030184Z",
     "iopub.status.busy": "2025-08-22T20:06:10.029838Z",
     "iopub.status.idle": "2025-08-22T20:06:10.036550Z",
     "shell.execute_reply": "2025-08-22T20:06:10.035671Z",
     "shell.execute_reply.started": "2025-08-22T20:06:10.030158Z"
    }
   },
   "source": [
    "## Slow Ingestion of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00b6e79-d4dc-47b0-8ebd-65beaccf9338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:03:09.154100Z",
     "iopub.status.busy": "2025-08-22T20:03:09.153764Z",
     "iopub.status.idle": "2025-08-22T20:03:33.390936Z",
     "shell.execute_reply": "2025-08-22T20:03:33.390214Z",
     "shell.execute_reply.started": "2025-08-22T20:03:09.154076Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorstore = QdrantVectorStore.from_documents(\n",
    "    docs,\n",
    "    OpenAIEmbeddings(model=os.environ[\"EMBEDDING_MODEL\"]),\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"documentations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b81911-6532-4d63-bfd9-021b2e32a975",
   "metadata": {},
   "source": [
    "## Agent Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e28e4c2-5b9d-4c81-b7a4-0fbe91bfe8cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:04:20.679970Z",
     "iopub.status.busy": "2025-08-22T20:04:20.679536Z",
     "iopub.status.idle": "2025-08-22T20:04:20.720553Z",
     "shell.execute_reply": "2025-08-22T20:04:20.719653Z",
     "shell.execute_reply.started": "2025-08-22T20:04:20.679942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='retriever_hugging_face_documentation' description='Search and return information about hugging face documentation, it includes the guide and Python code.' args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'> func=functools.partial(<function _get_relevant_documents at 0x7f1947ffcd60>, retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f19200b9970>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content') coroutine=functools.partial(<function _aget_relevant_documents at 0x7f195435e480>, retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f19200b9970>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_hugging_face_documentation\",\n",
    "    \"Search and return information about hugging face documentation, it includes the guide and Python code.\"\n",
    ")\n",
    "print(tool)\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant that helps users with thier queries\")\n",
    "llm = ChatOpenAI(model=os.environ[\"OPENAI_MODEL\"])\n",
    "llm_with_tools = llm.bind_tools(tools=[tool], parallel_tool_calls=False)\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb43343-9a6f-42cb-86e6-4380f928633c",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef13cd4-05a6-4084-a620-2e7b91d9a72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:04:44.698447Z",
     "iopub.status.busy": "2025-08-22T20:04:44.697792Z",
     "iopub.status.idle": "2025-08-22T20:04:45.111665Z",
     "shell.execute_reply": "2025-08-22T20:04:45.110828Z",
     "shell.execute_reply.started": "2025-08-22T20:04:44.698414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([tool]))\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75602459-d8ca-47b4-9518-3f38343ebfe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:04:52.857866Z",
     "iopub.status.busy": "2025-08-22T20:04:52.857582Z",
     "iopub.status.idle": "2025-08-22T20:05:12.863091Z",
     "shell.execute_reply": "2025-08-22T20:05:12.862330Z",
     "shell.execute_reply.started": "2025-08-22T20:04:52.857847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what do you know about efficient Training on Multiple CPUs using Intel chips in huggingface ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retriever_hugging_face_documentation (call_KI8YR28nBGQBgh79VWAYrU49)\n",
      " Call ID: call_KI8YR28nBGQBgh79VWAYrU49\n",
      "  Args:\n",
      "    query: Efficient Training on Multiple CPUs using Intel chips\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retriever_hugging_face_documentation\n",
      "\n",
      "\"\\n\\n# Efficient Training on Multiple CPUs\\n\\nWhen training on a single CPU is too slow, we can use multiple CPUs. This guide focuses on PyTorch-based DDP enabling distributed CPU training efficiently.\\n\\n## Intel\\u00ae oneCCL Bindings for PyTorch\\n\\n[Intel\\u00ae oneCCL](https://github.com/oneapi-src/oneCCL) (collective communications library) is a library for efficient distributed deep learning training implementing such collectives like allreduce, allgather, alltoall. For more information on oneCCL, please refer to the [oneCCL documentation](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html) and [oneCCL specification](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html).\\n\\nModule `oneccl_bindings_for_pytorch` (`torch_ccl` before version 1.12)  implements PyTorch C10D ProcessGroup API and can be dynamically loaded as external ProcessGroup and only works on Linux platform now\\n\\nCheck more detailed information for [oneccl_bind_pt](https://github.com/intel/torch-ccl).\\n\\n### Intel\\u00ae oneCCL Bindings for PyTorch installation:\\n\\nWheel files are available for the following Python versions:\\n\\n| Extension Version | Python 3.6 | Python 3.7 | Python 3.8 | Python 3.9 | Python 3.10 |\\n\\n| :---------------: | :--------: | :--------: | :--------: | :--------: | :---------: |\\n\\n| 1.13.0            |            | \\u221a          | \\u221a          | \\u221a          | \\u221a           |\\n\\n| 1.12.100          |            | \\u221a          | \\u221a          | \\u221a          | \\u221a           |\\n\\n| 1.12.0            |            | \\u221a          | \\u221a          | \\u221a          | \\u221a           |\\n\\n| 1.11.0            |            |\n",
      "\n",
      "\"\\n\\n# Efficient Training on CPU\\n\\nThis guide focuses on training large models efficiently on CPU.\\n\\n## Mixed precision with IPEX\\n\\nIPEX is optimized for CPUs with AVX-512 or above, and functionally works for CPUs with only AVX2. So, it is expected to bring performance benefit for Intel CPU generations with AVX-512 or above while CPUs with only AVX2 (e.g., AMD CPUs or older Intel CPUs) might result in a better performance under IPEX, but not guaranteed. IPEX provides performance optimizations for CPU training with both Float32 and BFloat16. The usage of BFloat16 is the main focus of the following sections.\\n\\nLow precision data type BFloat16 has been natively supported on the 3rd Generation Xeon\\u00ae Scalable Processors (aka Cooper Lake) with AVX512 instruction set and will be supported on the next generation of Intel\\u00ae Xeon\\u00ae Scalable Processors with Intel\\u00ae Advanced Matrix Extensions (Intel\\u00ae AMX) instruction set with further boosted performance. The Auto Mixed Precision for CPU backend has been enabled since PyTorch-1.10. At the same time, the support of Auto Mixed Precision with BFloat16 for CPU and BFloat16 optimization of operators has been massively enabled in Intel\\u00ae Extension for PyTorch, and partially upstreamed to PyTorch master branch. Users can get better performance and user experience with IPEX Auto Mixed Precision.\\n\\nCheck more detailed information for [Auto Mixed Precision](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/features/amp.html).\\n\\n### IPEX installation:\\n\\nIPEX release is following PyTorch, to install via pip:\\n\\n| PyTorch Version   | IPEX version   |\\n\\n| :---------------: | :----------:   |\\n\\n| 1.13              |  1.13.0+cpu    |\\n\\n| 1.12              |  1.12.300+cpu  |\\n\\n| 1.11              |  1.11.200+cpu  |\\n\\n| 1.10              |  1.10.100+cpu  |\\n\\npip install intel_extension_for_pytorch== -f https://developer.intel.com/ipex-whl-stable-cpu\\n\\nCheck more approaches for [IPEX installation](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/installation.html).\\n\\n### Usage in Trainer\\n\\nTo enable auto mixed precision with IPEX in Trainer, users should add `use_ipex`, `bf16` and `no_cuda` in training command arguments.\\n\\nTake an example of the use cases\n",
      "\n",
      "$torch_ccl_path/env/setvars.sh\\n\\n#### IPEX installation:\\n\\nIPEX provides performance optimizations for CPU training with both Float32 and BFloat16, you could refer [single CPU section](./perf_train_cpu).\\n\\nThe following \\\"Usage in Trainer\\\" takes mpirun in Intel\\u00ae MPI library as an example.\\n\\n## Usage in Trainer\\n\\nTo enable multi CPU distributed training in the Trainer with the ccl backend, users should add **`--ddp_backend ccl`** in the command arguments.\\n\\nLet's see an example with the [question-answering example](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering)\\n\\nThe following command enables training with 2 processes on one Xeon node, with one process running per one socket. The variables OMP_NUM_THREADS/CCL_WORKER_COUNT can be tuned for optimal performance.\\n\\n```shell script\\n\\n export CCL_WORKER_COUNT=1\\n\\n export MASTER_ADDR=127.0.0.1\\n\\n mpirun -n 2 -genv OMP_NUM_THREADS=23 \\\\\\n\\n python3 run_qa.py \\\\\\n\\n --model_name_or_path bert-large-uncased \\\\\\n\\n --dataset_name squad \\\\\\n\\n --do_train \\\\\\n\\n --do_eval \\\\\\n\\n --per_device_train_batch_size 12  \\\\\\n\\n --learning_rate 3e-5  \\\\\\n\\n --num_train_epochs 2  \\\\\\n\\n --max_seq_length 384 \\\\\\n\\n --doc_stride 128  \\\\\\n\\n --output_dir /tmp/debug_squad/ \\\\\\n\\n --no_cuda \\\\\\n\\n --ddp_backend ccl \\\\\\n\\n --use_ipex\\n\\nThe following command enables training with a total of four processes on two Xeons (node0 and node1, taking node0 as the main process), ppn (processes per node) is set to 2, with one process running per one socket. The variables OMP_NUM_THREADS/CCL_WORKER_COUNT can be tuned for optimal performance.\\n\\nIn node0, you need to create a configuration file which contains the IP addresses of each node (for example hostfile) and pass that configuration file path as an argument.\\n\\n```shell script\\n\\n cat hostfile\\n\\n xxx.xxx.xxx.xxx #node0 ip\\n\\n xxx.xxx.xxx.xxx #node1 ip\\n\\nNow, run the following command in node0 and **4DDP** will be enabled in node0 and node1 with BF16 auto mixed precision:\\n\\n```shell script\\n\\n export\n",
      "\n",
      "install intel_extension_for_pytorch\\n\\nSet the `--use_ipex` and `--jit_mode_eval` flags in the [`Trainer`] class to enable JIT mode with the graph optimizations:\\n\\n```bash\\n\\npython run_qa.py \\\\\\n\\n--model_name_or_path csarron/bert-base-uncased-squad-v1 \\\\\\n\\n--dataset_name squad \\\\\\n\\n--do_eval \\\\\\n\\n--max_seq_length 384 \\\\\\n\\n--doc_stride 128 \\\\\\n\\n--output_dir /tmp/ \\\\\\n\\n--no_cuda \\\\\\n\\n--use_ipex \\\\\\n\\n--jit_mode_eval\\n\\n## \\ud83e\\udd17 Optimum\\n\\nLearn more details about using ORT with \\ud83e\\udd17 Optimum in the [Optimum Inference with ONNX Runtime](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/models) guide. This section only provides a brief and simple example.\\n\\nONNX Runtime (ORT) is a model accelerator that runs inference on CPUs by default. ORT is supported by \\ud83e\\udd17 Optimum which can be used in \\ud83e\\udd17 Transformers, without making too many changes to your code. You only need to replace the \\ud83e\\udd17 Transformers `AutoClass` with its equivalent [`~optimum.onnxruntime.ORTModel`] for the task you're solving, and load a checkpoint in the ONNX format.\\n\\nFor example, if you're running inference on a question answering task, load the [optimum/roberta-base-squad2](https://huggingface.co/optimum/roberta-base-squad2) checkpoint which contains a `model.onnx` file:\\n\\nfrom transformers import AutoTokenizer, pipeline\\n\\nfrom optimum.onnxruntime import ORTModelForQuestionAnswering\\n\\nmodel = ORTModelForQuestionAnswering.from_pretrained(\\\"optimum/roberta-base-squad2\\\")\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"deepset/roberta-base-squad2\\\")\\n\\nonnx_qa = pipeline(\\\"question-answering\\\", model=model, tokenizer=tokenizer)\\n\\nquestion = \\\"What's my name?\\\"\\n\\ncontext = \\\"My name is Philipp and I live in Nuremberg.\\\"\\n\\npred = onnx_qa(question, context)\\n\\nIf you have an Intel CPU, take a look at \\ud83e\\udd17 [Optimum Intel](https://huggingface.co/docs/optimum/intel/index) which supports a variety of compression techniques (quantization, pruning, knowledge distillation) and tools for converting models to the\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "For efficient training on multiple CPUs using Intel chips in the Hugging Face ecosystem, the focus is on leveraging Intel technologies like the Intel oneAPI Collective Communications Library (oneCCL) and Intel Extension for PyTorch (IPEX).\n",
      "\n",
      "### Intel oneCCL Bindings for PyTorch\n",
      "Intel oneCCL is a library for efficient distributed deep learning training that provides collective operations like allreduce, allgather, and alltoall. It supports the PyTorch C10D ProcessGroup API and can be used for distributed CPU training. It can be installed via wheel files available for Python versions 3.7 to 3.10.\n",
      "\n",
      "### Intel Extension for PyTorch (IPEX)\n",
      "IPEX optimizes CPU performance for training models, especially benefiting Intel CPUs with AVX-512 or higher capabilities. It provides performance improvements using either Float32 or BFloat16 precision. BFloat16 is particularly supported on the 3rd Generation Xeon Scalable Processors and beyond, with added performance through Intel Advanced Matrix Extensions (AMX).\n",
      "\n",
      "### Efficient Training with DDP\n",
      "Distributed Data Parallel (DDP) can be implemented using `oneccl_bindings_for_pytorch` to enable distributed training across multiple CPUs efficiently. You can also use IPEX to enable mixed precision training to enhance performance by using `--use_ipex` and `--ddp_backend ccl` flags in your command line when training models using Hugging Face's `Trainer`.\n",
      "\n",
      "### Sample Setup\n",
      "To enable multi-CPU distributed training and use IPEX, you would set environment variables and run your training script. Here's a basic example command:\n",
      "\n",
      "```bash\n",
      "export CCL_WORKER_COUNT=1\n",
      "export MASTER_ADDR=127.0.0.1\n",
      "\n",
      "mpirun -n 2 -genv OMP_NUM_THREADS=23 \\\n",
      "python3 run_qa.py \\\n",
      "--model_name_or_path bert-large-uncased \\\n",
      "--dataset_name squad \\\n",
      "--do_train \\\n",
      "--do_eval \\\n",
      "--per_device_train_batch_size 12 \\\n",
      "--learning_rate 3e-5 \\\n",
      "--num_train_epochs 2 \\\n",
      "--max_seq_length 384 \\\n",
      "--doc_stride 128 \\\n",
      "--output_dir /tmp/debug_squad/ \\\n",
      "--no_cuda \\\n",
      "--ddp_backend ccl \\\n",
      "--use_ipex\n",
      "```\n",
      "\n",
      "This enables distributed training on multiple CPUs, optimizing for Intel architectures and making use of mixed precision with IPEX. For further enhancement, tools such as Intel's Optimum library offer additional model optimization techniques like quantization and pruning.\n",
      "\n",
      "If you need more information on using specific Intel tools or any other guidance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"what do you know about efficient Training on Multiple CPUs using Intel chips in huggingface ?\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413f66e-7e1b-45ff-b5e7-3343ad355afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
